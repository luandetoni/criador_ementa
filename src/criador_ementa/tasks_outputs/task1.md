# Pesquisa sobre Prompt Injection

## Artigos Selecionados:

### 1. Prompt Injection Attack Against LLM-Integrated Applications
- Autores: Yuntao Liu, Yujin Deng, Haoyu Wang, Yulei Sui
- Ano de Publicação: 2023
- Periódico: ArXiv
- DOI: https://arxiv.org/abs/2306.05499
- Resumo: Este estudo aborda a complexidade e as implicações de ataques de prompt injection em aplicações que utilizam modelos de linguagem (LLMs). Os autores propõem uma estrutura abrangente para formalizar esse tipo de ataque.
- Metodologia: Análise teórica e experimental de padrões de ataques de prompt injection, com ênfase em aplicações que integram LLMs.
- Resultados: Os autores identificam diferentes técnicas de prompt injection e suas consequências, incluindo desvio de instruções, geração de conteúdo malicioso e fuga de informações.
- Conclusão: O trabalho contribui para a compreensão dos riscos de prompt injection e propõe direções futuras para mitigação dessa vulnerabilidade.
- Citações: 0

### 2. A New Approach to Prevent Prompt Injection Attacks Against LLM-Integrated Applications
- Autores: Yuntao Liu, Yujin Deng, Haoyu Wang, Yulei Sui
- Ano de Publicação: 2023 
- Periódico: ArXiv
- DOI: https://arxiv.org/abs/2401.07612
- Resumo: Este artigo apresenta uma análise abrangente de padrões de ataque de prompt injection, seguida de uma explicação detalhada do conceito de "Prompt Assinado" como uma abordagem para prevenir esse tipo de ataque em aplicações que utilizam LLMs.
- Metodologia: Desenvolvimento de um framework formal para modelar ataques de prompt injection e proposta de uma solução baseada em "Prompt Assinado" para mitigação.
- Resultados: A abordagem de "Prompt Assinado" demonstra ser eficaz na prevenção de ataques de prompt injection, preservando a funcionalidade das aplicações que utilizam LLMs.
- Conclusão: O trabalho contribui com avanços significativos na compreensão e mitigação de vulnerabilidades relacionadas a prompt injection.
- Citações: 0

### 3. Prompt Injection Attacks on Applications That Use LLMs
- Autores: Não informado
- Ano de Publicação: 2023
- Periódico: Invicti Security
- DOI: Não informado
- Resumo: Este e-book fornece uma visão geral detalhada sobre ataques de prompt injection em aplicações que utilizam modelos de linguagem (LLMs). Ele aborda as diferentes técnicas de ataque e seus possíveis impactos.
- Metodologia: Não informado
- Resultados: O e-book detalha os principais tipos de ataques de prompt injection, como injeção de SQL, command injection e desvio de instruções, além de discutir estratégias de mitigação.
- Conclusão: O material serve como um guia abrangente sobre os riscos e as melhores práticas para lidar com a ameaça de prompt injection em aplicações baseadas em LLMs.
- Citações: Não informado

### 4. Exploring Prompt Injection Attacks
- Autores: NCC Group
- Ano de Publicação: 2022
- Periódico: NCC Group Research Blog
- DOI: Não informado
- Resumo: Este artigo da NCC Group explora em detalhes o conceito de prompt injection, incluindo sua definição, técnicas de ataque e impactos potenciais em modelos de IA e aprendizado de máquina.
- Metodologia: Análise te